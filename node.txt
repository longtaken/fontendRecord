第1章
node简介

1.1 node诞生历程
2009年5月，Ryan Dahl在github上发布最初的版本

1.4 node的特点
1.4.1 异步I/O
1.4.2 事件与回调函数

1.4.3 单线程
      单线程弱点：无法利用多核CPU、错误会引起整个应用退出，应用健壮性值得考验、大量计算占用CPU导致无法继续调用异步I/O
      
      node采用了与Web Workers相同的思路来解决单线程中大计算量的问题：child_process。
      子进程的出现，意味着node可以从容应对单线程在健壮性和无法利用多核CPU方面的问题。通过将计算分发到各个子进程，可以将大量计算分解掉，然后再通过进程之间的事件消息来传递结果，这可以很好地保持应用模型的简单和低依赖。
      通过Master-Worker的管理方式，也可以很好地管理各个工作进程，以达到更高的健壮性

1.4.4 跨平台


1.5 node的应用场景

1.5.1 I/O密集型
      I/O密集的优势主要在于node利用事件循环的处理能力，而不是启动每一个线程为每一个请求服务，资源占用极少
      
1.5.2 是否不擅长CPU密集型业务
      CPU密集型应用给node带来挑战主要是：由于javascript单线程的原因，如果有长时间运行的计算（循环），将会导致CPU时间片不能释放，使得后续I/O无法发起。但是适当调整和分解大型运算任务为多个小任务，使得运算能够适时释放，不阻塞I/O调用的发起。
      关于CPU密集型应用，node的异步I/O已经解决了在单线程上CPU与I/O之间阻塞无法重叠利用的问题，I/O阻塞造成的性能浪费远比CPU的影响小。
      长时间的运行计算，如果它的耗时超过普通阻塞I/O的耗时，那么应用场景需要重新评估，这类计算比阻塞I/O还影响效率（纯计算场景），根本没有I/O。此类应用场景或许应当采用多线程的方式进行计算。
      node没有提供多线程用于计算支持，但有两个方式来充分利用CPU：
      1，node可以通过编写C/C++扩展的方式更高效地利用CPU，将一些V8不能做到性能极致的地方通过C/C++实现。
      2，如果单线程的node不能满足需求，那么通过子进程的方式，将一部分node进程当做常驻服务进程用于计算，然后利用进程间的消息来传递结果，将计算与I/O分离，这样能充分利用多CPU。
      
1.5.3 与遗留系统和平共处

1.5.4 分布式应用
      分布式应用意味着对可伸缩性的要求非常高。
      node高效利用并行I/O的过程，也是高效实用数据库的过程。对于node，这个行为只是一次普通的I/O。对于数据库而言，却是一次复杂的计算，所以也是进而充分压榨硬件资源的过程。
      
1.6 node的使用者 
1.7 参考资源



第2章
模块机制

2.1 commonjs规范
2.1.1 commonjs的出发点

2.1.2 commonjs的模块规范
      1，模块引用
         require()方法接受模块标识，以此引入一个模块的api到当前上下文中
      2，模块定义
         对应引入的功能，上下文提供了exports对象用于导出当前模块的方法或者变量，并且它是唯一导出的出口。
         模块中还存在一个module对象，它代表模块自身，而exports是module的属性。
         在node中，一个文件就是一个模块，将方法挂载在exports对象上作为属性即可定义导出的方式
         //a.js  exports.add=fn; b.js  var a = require('a');a.add();
      3，模块标识
         模块标识其实就是传递给require()方法的参数，它必须是符合小驼峰命名的字符串，或者以.、..开头的相对路径，或者绝对路径。它可以没有后缀.js
      commonjs构建的模块导出和引入机制使得用户不必考虑变量污染
2.2 node的模块实现
    node的实现并非完全按照规范，而是对模块规范进行取舍，同事增加少许自身需要的特性
    node引入模块步骤
        1，路径分析。2，文件定位。3，编译执行。
    node模块分为两类
        一类是node提供的核心模块。
           核心模块在node源代码的编译过程中，编译进了二进制执行文件。在node进程启动时，部分核心模块就被直接加载进内存中，所以这部分核心模块引入时，文件定位和编译执行两个步骤可以省略。并且在路径分析中优先判断，所以它加载速度是最快的
        一类是用户编写的文件模块。
           文件模块是在运行时动态加载，需要完成的路径分析、文件定位、编译执行过程，速度比核心模块慢。
           
2.2.1 优先从缓存加载
    node引入的模块会进行缓存，以减少二次引入时的开销。不同于浏览器缓存只文件，node缓存的是编译和执行之后的对象。
    不论是核心模块还是文件模块，require()方法对相同模块的二次加载都一律采用缓存优先的方式，这是第一优先级的。不同之处在于核心模块的缓存检查先于文件模块的缓存检查
    
2.2.2 路径分析和文件定位
    因为标识符有几种形式，对于不同的标识符，模块的查找和定位有不同程度上的差异
    1，模块标识符分析
      require方法接受一个标识符作为参数，在node实现中，正是基于这样一个标识符进行模块查找。模块标识符在node中主要分以下几类
      - 核心模块，如http，fs，path等
      - .或..开始的相对路径文件模块
      - 以/开始的绝对路径文件模块
      - 非路径形式的文件模块，如自定义的connect模块
      核心模块
      核心模块的优先级仅次于缓存加载，在node的源代码编译过程中已经编译为二进制代码，其加载过程最快。如果试图加载一个与核心模块标识符相同的自定义模块，那是不会成功的。如果自己编写了一个http用户模块，想要加载成功，必须选择一个不同的标识符或者换用路径的方式。
      以路径形式的文件模块
      以.、..和/开始的标识符，这里都被当做文件模块来处理。在分析文件模块时，require方法会将路径转为真实路径，并以真实路径作为索引，将编译执行后的经过存放到缓存中，以使二次加载时更快。由于文件模块给node指明了确切的文件位置，所以在查找过程中可以节约大量时间，加载速度慢于核心模块。
      自定义模块
      自定义模块指的是非核心模块，也不是路径形式的标识符。它是一种特殊的文件模块，可能是一个文件或者包的形式。这类模块的查找是最费时的，也是所有方式中最慢的一种。
      * 模块路径是node在定位文件模块的具体文件时定制的查找策略，具体表现为一个路径组成的数组。 
      模块路径的生成规则：当前文件目录下的node_modules目录。父目录下的node_modules目录。父目录的父目录下的node_modules目录。沿路径向上逐级递归，直到根目录下的node_modules目录。
      生成方式与js的原型链或者作用域的查找方式类似。加载过程中node会逐个尝试模块路径中的路径，直到找到目标文件为止。当前文件的路径越深，模块查找耗时会越多，这是自定义模块的加载速度是最慢的原因。
    2，文件定位
      从缓存加载的优化策略使得二次引入时不需要路径分析、文件定位和编译执行的过程，大大提高了再次加载模块时的效率
      文件扩展名分析
        require在分析标识符的过程中，会出现标识符不包含文件扩展名的情况。commonjs模块规范也允许在标识符中不包含文件扩展名，这种情况下，node会按.js、.json、.node的次序补足扩展名，依次尝试。
        在尝试的过程中，需要调用fs模块同步阻塞式地判断文件是否存在。因为node是单线程的，所以这里是一个会引起性能问题的地方。
        tips1：如果是.node和.json文件，在传递给require()的标识符中带上扩展名，会加快一点速度。
        tips2：同步配合缓存，可以大幅度缓解node单线程中阻塞式调用的缺陷
      目录分析
        在分析标识符的过程中，require()通过分析文件扩展名之后，可能没有查找到对应文件，但却得到一个目录，这在引入自定义模块和逐个模块路径进行查找时经常会出现，此时node会将目录当做一个包来处理
        在这个过程中，node对commonjs包规范进行了一定程度的支持。
        首先，node在当前目录下查找package.json（commonjs包规范定义的包描述文件），通过JSON.parse()解析出包描述对象，从中取出main属性指定的文件名进行定位。如果文件名缺少扩展名，将会进入扩展名分析步骤。
        如果main属性指定的文件名错误，或者没有package.json文件，node会将index当做默认文件名，然后依次查找index.js、index.json、index.node
        如果在目录分析过程中没有定位成功任何文件，则自定义模块进入下一个模块路径进行查找。如果模块路径数组都被遍历完毕，依然没找到目标文件，则抛出查找失败的异常。
        
2.2.3 模块编译
    在node中，每个文件模块都是一个对象，它的定义如下：
    function Module(id, parent){
      this.id = id;
      this.exports = {};
      if (parent && parent.children) {
        parent.children.push(this);
      }
      this.filename = null;
      this.loaded = false;
      this.children = [];
    }
    编译和执行是引入文件模块的最后一个阶段。定位到具体的文件后，node会新建一个模块对象，然后根据路径载入并编译。对于不同的文件扩展名，其载入方法也不同
        .js文件。通过fs模块同步读取文件后编译执行
        .node文件。这是用c/c++编写的扩展文件，通过dlopen()方法加载最后编译生产的文件
        .json文件。通过fs模块同步读取文件后，同JSON.parse()解析返回结果
        其余扩展名，都被当做.js文件载入
        每一个编译成功的模块都会将其文件路径作为索引缓存在Module._cache对象上，以提高二次引入的性能
        根据不同的文件扩展名，node会调用不同的读取方法，如.json文件的调用如下：
            Module._extension['.json'] = function(module, filename){
              var content = NativeModule.require('fs').readFileSync(filename, 'utf8');
              try {
                module.exports = JSON.parse(stripBOM(content));
              } catch(e) {
                e.message = filename + ':' + e.message;
                throw e;
              }
            }
            Module._extension会被赋值给require()的extensions属性，所以可以console.log(require.extensions);//{ '.js': [Function], '.json': [Function], '.node': [Function] }

    确定文件扩展名后，node将调用具体的编译方式来将文件执行后返回给调用者
      1.javascript模块的编译
        在编译过程中，node对获取的JS文件内容进行了头尾包装。
        在头部添加了(function (exports, require, module, __filename, __dirname) {\n, \n});
        这样每个模块文件之间都进行了作用域隔离。包装后的代码会通过vm原生模块的runInThisContext()方法执行(类似eval，只是具有明确上下文，不污染全局)，返回一个具体的function对象。最后，将当前模块对象的exports属性、require方法、module（模块对象自身），以及在文件定位中得到的完整文件路径和文件目录作为参数传递给这个function执行
        这就是这些变量并没有定义在每个模块文件中却存在的原因。在执行之后，模块的exports属性被返回了调用方。exports属性上的任何方法和属性都可以被外部调用到，但是模块中的其余变量或属性则不可直接被调用。
        这就是node对commonjs模块规范的实现。
        exports对象时通过形参的方式传入的，直接赋值形参会改变形参的引用，但不能改变作用域外的值（var a=10; !function(a){a=11;}(); a//10 ）
      2.c/c++模块的编译
        node调用process.dlopen()方法进行加载和执行。在node的架构下，dlopen()方法在windows和*nix平台下分别有不同的实现，通过libuv兼容层进行了封装。
        实际上，.node的模块文件并不需要编译，因为它是编写c/c++模块后编译生成的，所以只有加载和执行的过程。在执行过程中，模块的exports对象与.node模块产生联系，然后返回给调用者。
        c/c++模块给node使用者带来的优势主要是执行效率方面的，劣势则是c/c++模块的编写门槛高
      3.JSON文件的编译
        .json文件的编译是3中方式中最简单的。node利用fs模块同步读取JSON文件的内容之后，调用JSON.parse方法得到对象，然后将它赋值给模块对象的exports，以供外部调用
        JSON文件在用作项目的配置文件时比较有用。如果你定义了一个JSON文件作为配置，就不必调用fs模块去异步读取和解析，直接调用require引入即可。能享受模块缓存的便利，二次引入没有性能影响

2.3 核心模块
    node的核心模块在编译成可执行文件的过程中被编译进了二进制文件。核心模块分为c/c++编写和js编写两部分，其中c/c++文件存放在node项目的src目录下，js放在lib目录下

2.3.1 js核心模块的编译过程
    1.转存为c/c++代码
      node采用v8附带的js2c.py工具，将所有内置的js代码（src/node.js和lib/*.js）转换成c++里的数组，生产node_natives.h头文件
      在这个过程，js代码以字符串的形式存储在node命名空间中，是不可直接执行的。在启动node进程时，js代码直接加载进内存中。在加载过程中，js核心模块经历标识符分析后直接定位到内存中，比普通的文件模块从磁盘中一出一出查要快很多。
    2.编译js核心模块
      lib目录下的所有模块文件也没有定义require、module、exports这些变量。在引入js核心模块过程中，也经历了头尾包装的过程，然后才执行和导出exports对象。与文件模块有区别的地方在于：获取源代码的方式（核心模块是内存中加载的)以及缓存执行结果的位置。
      js核心模块的定义，源文件通过process.binding('natives')取出，编译成功的模块缓存到NativeModule._cache对象上，文件模块则缓存到Module._cache对象上：
      function NativeModule(id) {
        this.filename = id + '.js';
        this.id = id;
        this.exports = {};
        this.loaded = false;
      }
      NativeModule._source = process.binding('natives');
      NativeModule._cache = {};

2.3.2 c/c++核心模块的编译过程
    在核心模块中，有些模块全部由c/c++编写，有些模块则由c/c++完成核心部分，其他部分则由js实现包装或向外导出，以满足性能需求。c++为核心，JS实现封装的模式是node能够提高性能的常见方式。
    纯c/c++编写的部分统一称为内建模块，因为它们通常不被用户直接调用。node的buffer、crypto、evals、fs、os等模块都是部分通过c/c++编写
    1.内建模块的组织形式
    struct node_module_struct {
      int version;
      void *dso_handle;
      const char * filename;
      void (*register_func) (v8::Handle<v8::Object> target);
      const char *modname;
    }      
    每一个内建模块在定义之后，都通过NODE_MODULE宏将模块定义到node命名空间中，模块的具体初始化方法挂载为结构的register_func成员：
    #define NODE_MODULE(modname, regfunc)
      extern "C" {
        NODE_MODULE_EXPORT node::node_module_struct modname ## _module =
        {
          NODE_STANDARD_MODULE_STUFF,
          regfunc,
          NODE_STRINGIFY(modname)
        };
      }
      node_extensions.h文件将这些散列的内建模块统一放进了一个叫node_module_list的数组中，这些模块有node_buffer,node_crypto,node_evals,node_fs,...
      node提供了get_builtin_module方法从node_module_list数组取出这些模块
      内建模块优势在于：本身由c/c++编写，性能优于脚本语言；在进行文件编译时，它们被编译进二进制文件。一旦node执行，它们被直接加载进内存中，无须再次做标识符定位、文件定位、编译等过程，直接可以执行
    2.内建模块的导出
      在node的所有模块类型中，存在（内建模块(c/c++)->核心模块(js)->文件模块）的依赖层级关系，文件模块可能会依赖核心模块，核心模块可能会依赖内建模块。
      通常，不推荐文件模块直接调用内建模块。如需调用，直接调用核心模块即可，因为核心模块中基本都封装了内建模块
      node在启动时，会生成一个全局变量process，并提供Binding()方法来协助加载内建模块
      在加载内建模块时，先创建一个exports空对象，然后调用get_builtin_module方法取出内建模块对象，通过执行register_func填充exports对象，最后将exports对象按模块名缓存，并返回给调用方完成导出。

2.3.3 核心模块的引入流程
    os原生模块的引入流程
    NODE_MODULE(node_os, reg_func) -> get_builtin_module('node_os') -> process.binding('os') -> NativeModule.require('os') -> require('os')  

2.3.4 编写核心模块
    核心模块被编译进二进制文件需要遵循一定规则
    page26

2.4 c/c++扩展模块
    js的典型弱点是位运算，参照java的位运算实现，但是java位运算是int型数字的基础上进行，而js只有double型数据类型，再进行位运算过程中需要转成int型，所以js做位运算效率不高，需要编写c/c++扩展模块来提升性能

2.4.1 前提条件
    gyp项目生成工具
    v8引擎c++库
    libuv库
    node内部库

2.4.2 c/c++扩展模块的编写
    普通的扩展模块与内建模块的区别在于无须将源代码编译进node，而是通过dlopen方法动态加载。
    编写普通扩展模块时，无须将源代码编译进node命名空间，也不需要提供头文件

2.4.3 c/c++扩展模块的编译
    
2.4.4 c/c++扩展模块的加载

2.5 模块调用栈
    
2.6 包与NPM
    
2.6.1 包结构
    包实际上是一个存档文件，即一个目录直接打包为.zip或tar.gz格式的文件，安装后解压还原目录。
    完全符合commonjs规范的包目录应该包含
    package.json：包描述文件
    bin：用于存放可执行二进制文件的目录
    lib：用于存放js代码的目录
    doc：用于存放文档的目录
    test：用于存放单元测试用例的代码

2.6.2 包描述文件与NPM
    name：包名，规范定义它需要由小写的字母和数字组成，可以包含.\_-，但不允许出现空格。包名必须是唯一的，以免对外公布时产生重名冲突的误解。不建议在包名中附带node或js重复标识它是js或node模块
    description：包简介
    version：版本号
    keywords： 关键词数组，npm中用来做分类搜索
    maintainers：包维护者列表，npm通过该属性进行权限认证
    contributors：贡献者列表
    bugs：一个可以反馈bug的网页地址或邮件地址
    licenses：当前包所使用的许可证列表，表示这个包可以在哪些许可证下使用
    repositories：托管源代码的位置列表，表明可以通过哪些方式和地址访问包的源代码
    dependencies：使用当前包所需要依赖的包列表。npm会通过这个属性帮助自动加载依赖的包

    可选
    homepage：当前包的网站地址
    os：操作系统支持列表
    CPU：CPU架构的支持列表，arm mips ppc sparc x86 x86_64
    engine：支持的js引擎列表，ejs flusspferd gpsee jsc spidermonkey narwhal node v8
    builtin：标志当前包是否内建在底层系统的标准组件
    directories：包目录说明
    implements：实现规范的列表
    scripts：脚本说明对象

    在包规范的区别在于多了
    author：包作者
    bin：一些包做着希望包可以作为命令行工具使用。配置好bin字段后，通过npm i package_name -g命令可以将脚本添加到执行路径中，之后可以在命令行直接执行。node-gyp就是这样安装。
    main：模块引入方法require在引入包时，会优先检查这个字段，并将其作为包中其余模块的入口，如果不存在这个字段，require会查找包目录下的index.js index.node index.json文件作为默认入口
    devDependencies：一些模块只在开发是需要的依赖

2.6.3 NPM常用功能
    commonjs包规范是理论，npm是一种实践。npm至于node，相当于gem之于ruby，pear之于php。
    1.查看帮助
      npm help <command>查看具体命令
      npm -v 版本
    2.安装依赖包
      npm install 安装好依赖包后，直接在代码调用require('xx')即可引入该包
      全局安装
        -g是将一个包安装为全局可用的执行命令。根据描述文件中bin字段配置，将实际脚本链接到与node可执行文件相同的路径下：'bin': {'express': './bin/express'}
        通过全局模式安装的所有模块包都被安装进了一个统一的目录下，通过path.resolve(process.execPath,'..','..','lib','node_modules')推算出来
        如果node可执行文件的位置是/user/local/bin/node，那么模块目录就是/usr/local/lib/node_module。通过软链接的方式将bin字段配置的可执行文件链接到node的可执行目录下
      本地安装
        本地安装只需为npm指明package.json文件所在的位置即可：它可以是一个包含package.json的存档文件，也可以是一个url地址，也可以是一个目录下package.json文件的目录位置
      从非官方源安装
        npm install underscore --registry=http://registry.url
        指定默认源
        npm config set registry http://registry.url
    3.npm钩子命令
      package.json中scripts字段让包安装或者卸载过程中提供钩子机制，'scripts': {'install':'install.js'}
    4.发布包
      编写模块
        保存xx.js
      初始化包描述文件
        npm init，创建package.json文件
      注册包仓库账号
        注册账号命令是npm adduser
      上传包
        npm publish <folder> 在package.json目录下执行npm publish . 开始上传包
      安装包
        npm i xx
      管理包权限
        npm owner ls eventproxy
        npm owner add eventproxy
        npm owner rm eventproxy
      分析包
        npm ls

2.6.4 局域npm
    搭建自己的npm仓库

2.6.5 npm潜在问题
    包质量良莠不齐

2.7 前后端共用模块
    
2.7.1 模块的侧重点
    
2.7.2 AMD规范
    AMD规范是commonjs模块规范的一个延伸,模块定义：
    define(id?, dependencies?, factory);
    AMD模块需要用define定义一个模块，而在node实现中是隐式包装的，它们的目的是作用域隔离，仅在需要的时候被引入，避免掉过去那种通过全局变量或全局命名空间的方式。

2.7.3 CMD规范
    与AMD规范的区别在于定义模块和依赖引入的部分
    AMD需要在声明模块的时候指定所有的依赖，通过形参传递依赖到模块内容中：
    define(['dep1', 'dep2'], function (dep1,dep2) { return function () {}; });
    
    CMD模块更接近于node对commonjs规范的定义：
    define(factory)

    在依赖部分，CMD支持动态引入：
    define(function(require, exports, module) {  });
    require、exports和module通过形参传递给模块，在需要依赖模块时，随时调用require引入即可

2.7.4 兼容多种模块规范
    兼容node、AMD、CMD以及常见浏览器环境：
    (function (name, definition) {
      // 检测上下文环境是否为AMD或CMD
      var hasDefine = typeof define === 'function';

      // 检查上下文环境是否为node
      var hasExports = typof module !== 'undefined' && module.exprots;

      if (hasDefine) {
        // AMD/CMD环境
        define(definition);
      } else if (hasExports) {
        // 定义为普通node模块
        module.exports = definition();
      } else {
        // 将模块的执行结果挂在window变量中，在浏览器this指向window对象
        this[name] = deinition();
      }

    })('test', function () {
      var test = function () {};
      return test;
    });

2.8 总结
2.9 参考资源


第3章 异步I/O
    与node事件驱动、异步I/O设计理念比较相近的nginx采用C编写，性能优异。与node区别在于nginx具备面向客户端管理连接的强大能力，但它的背后依然受限于各种同步方式的编程语言。node既可以作为服务器端去处理客户端带来的大量并发请求，也能作为客户端向网络中的各个应用进行并发请求。

3.1 为什么要异步I/O
    web应用已经不再是单台服务器就能胜任的时代，在跨网络的解构下，并发已经是现代变成中的标准配置了。

3.1.1 用户体验
    同步方式时间为M+N，异步方式时间为max(M+N)

3.1.2 资源分配
    计算机在发展过程中将组件进行了抽象，分为I/O设备和计算设备
    假设业务场景中有一组互不相关的任务需要完成，主流方法有两种：
      1.单线程串行依次执行
        串行执行的缺点在于性能，任意一个略慢的任务都会导致后续执行代码被阻塞
        在计算机资源中，通常I/O与CPU计算之间是可以并行进行的
        同步的编程模型导致的问题是，I/O的进行会让后续任务等待，造成资源不能被更好利用

      2.多线程并行完成
        如果创建多线程的开销小于并行执行，那么多线程的方式是首选的。
        多线程的代价在于创建线程和执行期线程上下文切换的开销较大。
        在复杂业务中，多线程编程经常面临锁、状态同步等问题。
        多线程在多核CPU上能够有效提升CPU的利用率
    
    node利用单线程，远离多线程死锁、状态同步问题，利用异步I/O，让单线程远离阻塞，更好利用cpu
    异步I/O可以算作ndoe特色，node是首个大规模将异步I/O应用在应用层上平台，力求在单线程上将资源分配得更高效
    为了弥补单线程无法利用多核CPU的缺点，node提供了类似前端中web workers的子进程，该子进程可以通过工作进程高效利用CPU和I/O
    异步I/O的提出是期望I/O的调用不再阻塞后续运算，将原有等待I/O完成的时间分配给其他需要的业务去执行

3.2 异步I/O实现现状

3.2.1 异步I/O与非阻塞I/O
    从计算机内核I/O而言，异步/同步和阻塞/非阻塞实际上是两回事
    操作系统内核对于I/O只有两种方式：阻塞与非阻塞。在调用阻塞I/O时，应用程序需要等待I/O完成才返回结果
    
    阻塞I/O的一个特点是调用之后一定要等到系统内核层面完成所有操作后，调用才结束
    以读取磁盘的一段文件为例，系统内核在完成磁盘寻道、读取数据、复制数据到内存之后，这个调用才结束

    阻塞I/O造成CPU等待I/O，浪费等待时间，CPU的处理能力不能得到充分利用。为了提高性能，内核提供了非阻塞I/O。非阻塞I/O与阻塞I/O的差别为调用之后会立即返回
    非阻塞I/O返回之后，CPU的时间片可以用来处理其他事务
    非阻塞I/O存在问题是由于完整的I/O没有完成，立即返回的并不是业务期望的数据，应用程序需要重复调用I/O操作来确认是否完成，这种重复调用判断操作是否完成的技术叫做轮询。
    非阻塞I/O需要轮询去确认是否完全完成数据获取，会让CPU处理状态判断，是对CPU资源的浪费。

    轮询技术
    read 重复调用来检查I/O的状态来完成完整数据的读取。在得到最终数据前，CPU一直耗用在等待上。
    select 在read基础上改进。通过对文件描述符上的事件状态来进行判断。select轮询采用1024长度的数组来存储状态，所以它最多可以同时检查1024个文件描述符
    poll 较select有所改进，采用链表的方式避免数组长度的限制，其次能避免不需要的检查。但当文件描述符较多的时候，性能还是低下
    epoll Linux下效率最高的I/O事件通知机制，在进入轮询的时候如果没有检查到I/O事件，将会进行休眠，直到事件将它唤醒。它是真实利用事件通知、执行回调的方式，而不是遍历查询，所以不会浪费CPU
    kqueue 与epoll类似，仅在FreeBSD系统下存在
    轮询技术对于应用程序而言，仍只算一种同步，因为应用程序仍需要等待I/O完全返回。等待期间，CPU要么用于遍历文件描述符状态，要么用于休眠等待事件发生

3.2.2 理想的非阻塞异步I/O
    完美的异步I/O应该是应用程序发起的非阻塞调用，无须通过遍历或者事件唤醒等方式轮询，可以直接处理下一个任务，只需在I/O完成后通过信号或回调数据传递给应用程序
    Linux存在这样的方式，原生提供一种异步I/O方式（AIO）就是通过信号或回调来传递数据。
    AIO仅支持内核I/O中的O_DIRECT方式读取，导致无法利用系统缓存

3.2.3 现实的异步I/O
    通过让部分进程进行阻塞I/O或者非阻塞I/O加轮询技术来完成数据获取，让一个线程进行计算处理，通过线程之间的通信将I/O得到的数据进行传递，这就模拟实现了异步I/O    
    node是单线程，这里的单线程仅仅只是js执行在单线程中。在node中，内部完成I/O任务的另有线程池

3.3 node的异步I/O
    
3.3.1 事件循环
    node自身的执行模型--事件循环，正式它是的回调函数十分普遍
    在进程启动时，node便会创建一个类似于while(1)的循环，每执行一次循环体的过程称为Tick。每个Tick的过程就是查看是否有事件待处理，如果有，就取出事件及其相关的回调函数。如果存在关联的回调函数，就执行它们。然后进入下一个循环，如果不再有事件处理，就退出进程

3.3.2 观察者
    每个事件循环中有一个或多个观察者，而判断是否有事件要处理的过程就是向这些观察者询问是否有要处理的事件。
    浏览器采用了类似机制。事件可能来自用户的点击或者加载某些文件时产生，而这些产生的事件都有对应的观察者。在node中，事件主要来源于网络请求、文件I/O等，这些事件对应的观察者有文件I/O观察者、网络I/O观察者等。观察者将事件进行了分类
    事件循环是一个典型的生产者/消费者模型。异步I/O、网络请求等则是事件的生产者，源源不断为node提供不同类型的事件，这些事件被传递到对应的观察者那里，事件循环则从观察者那里取出事件并处理

3.3.3 请求对象
    windows下异步I/O（利用IOCP实现）
    对于一般的（非异步）回调函数，函数由我们自行调用
    对于node中异步I/O调用而言，回调函数不由开发者调用。
    从js发起调用到内核执行完I/O操作的过渡过程中，存在一种中间产物，叫做请求对象
    fs.open = function(path, flags, mode, callback) {
      binding.open(pathModule._makeLong(path), stringToFlags(flags), mode, callback);
    };
    fs.open的作用是根据指定路径和参数去打开一个文件，从而得到一个文件描述符，这是后续所有I/O操作的初始操作。
    从JS调用node的核心模块，核心模块调用C++内建模块，内建模块通过libuv进行系统调用，这是node里经典的调用方式。

    请求对象时异步I/O过程中的重要中间产物，所有的状态都保存在这个对象中，包括送入线程池等待执行以及I/O操作完毕后的回调处理

3.3.4 执行回调
    组装好请求对象、送入I/O线程池等待执行，实际上完成了异步I/O的第一部分，回调通知是第二部分。

    事件循环、观察者、请求对象、I/O线程池这四者共同构成了node异步I/O模型的基本要素

3.3.5 小结
    js是单线程，node自身是多线程的，只是I/O线程使用的CPU较少。
    除了用户代码无法并行执行外，所有的I/O（磁盘I/O和网络I/O）则是可以并行起来的

3.4 非I/O的异步API
    node中存在一些与I/O无关的异步API：setTimeout、setInterval、setImmediate、process.nextTick

3.4.1 定时器
    setTimeout、setInterval与浏览器API一致，实现原理与异步I/O类似，只是不需要I/O线程池的参与。
    调用setTimeout、setInterval创建的定时器会被插入到定时器观察者内部的一个红黑树中。每次Tick执行时，会从该红黑树中迭代取出定时器对象，检查是否超过定时时间，如果超过，就形成一个时间，它的回调函数将立即执行。
    定时器的问题在于，它并非精确的。尽管事件循环十分快，但如果某一次循环占用的时间较多，那么下次循环时，它也许已经超时很久了。

3.4.2 process.nextTick
    由于事件循环自身的特点，定时器的精确度不够。采用定时器需要动用红黑树，创建定时器对象和迭代等操作，而setTimeout(fn, 0)的方式较为浪费性能。process.nextTick方法的操作相对较为轻量
    process.nextTick = function(callback) {
      if (process._exiting) return;
      if (tickDepth >= process.maxTickDepth) maxTickWarn();

      var tock = { callback: callback };
      if (process.domain) tock.domain = process.domain;
      nextTickQueue.push(tock);
      if (nextTickQueue.length) process._needTickCallback();
    };
    每次调用process.nextTick方法，只会讲回调函数放入队列中，在下一轮Tick时取出执行。定时器中采用红黑树的操作时间复杂度为O(lg(n)),nextTick的时间复杂度为O(1)。相比之下，process.nextTick更高效

3.4.3 setImmediate
    setImmediate方法与process.nextTick方法十分类似，都是将回调函数延迟执行。
    process.nextTick(function () {
      console.log('1');
    });
    setImmediate(function () {
      console.log('2');
    });
    console.log('0');
    //0 -> 1 -> 2
    process.nextTick中的回调函数执行优先级高于setImmediate
    原因在于事件循环对观察者的检查是有先后顺序的，process.nextTick属于idle观察者，setImmediate属于check观察者。在每一个轮循环中，idle观察者先于I/O观察者，I/O观察者先于check观察者
    在具体实现上，process.nextTick的回调函数保存在一个数组中，setImmediate的结果保存在链表中。
    在行为上，process.nextTick在每轮循环中会将数组中的回调函数全部执行完，而setImmediate在每轮循环中执行链表的一个回调函数。

3.5 事件驱动与高性能服务器
    事件驱动的实质，通过主循环加事件触发的方式运行程序
    异步I/O不仅仅应用在文件操作中。对于网络套接字的处理，node也应用到了异步I/O，网络套接字上侦听到的请求都会形成事件交给I/O观察者。事件循环会不停地处理这些网络I/O事件。如果JS有传入回调函数，这些事件将会最终传递到业务逻辑层进行处理。利用node构建web服务器，正式在这样一个基础上实现的。
    
    服务器模型：
    同步式： 对于同步式的服务，一次只能处理一个请求，并且其余请求都处于等待状态
    每进程/每请求： 为每个请求启动一个进程，这样可以处理多个请求，但它不具备扩展性，因为系统资源固定
    每线程/每请求： 为每个请求启动一个线程来处理。尽管线程比进程要轻量，但是由于每个线程都占用一定内存，当大并发请求到来时，内存将会很快用光，导致服务器缓慢。每线程/每进程的扩展性比每进程/每请求的方式要好，但对于大型站点而言依然不够

    每线程/每请求的方式被Apache采用。
    node通过事件驱动的方式处理请求，无须为每一个请求创建额外的对应线程，可以省掉创建线程和销毁线程的开销，同时操作系统在调度任务时因为线程较少，上下文切换的代价很低。这使得服务器能从容处理请求，即使在大量连接的情况下，也不受线程上下文切换开销的影响，这是node高性能的一个原因

    nginx摒弃多线程的方式，采用和node相同的事件驱动。nginx大有取代Apache之势
    node具有与nginx相同的特性，不同之处在于nginx采用纯C编写，性能较高，但是它仅适合于做web服务器，用于反向代理或负载均衡等服务，在处理具体业务方面较为欠缺。
    node则是一套高性能的平台，可以利用它构建与nginx相同的功能，也可以处理各种具体业务，而且与背后的网络保持异步畅通。

3.6 总结
    事件循环是异步实现的核心，它与浏览器中的执行模型基本保持一致。

3.7 参考资源


第4章 异步编程
4.1 函数式编程

4.1.1 高阶函数
    在通常语言中，函数的参数只接受基本的数据类型或是对象引用，返回值也只是基本数据类型和对象引用。
    高阶函数则是可以把函数作为参数，或是将函数作为返回值的函数。

4.1.2 偏函数用法
    偏函数用法是指创建一个调用另外一个部分——参数或变量已经预置的函数——的函数的用法
    var toString = Object.prototype.toString;
    var isString = function (obj) {
      return toString.call(obj) == '[object String]';
    };
    var isFunction = function (obj) {
      return toString.call(obj) == '[object Function]';
    };

    var isType = function (type) {
      return function (obj) {
        return toString.call(obj) == '[object ' + type + ']';
      };
    };
    var isString = isType('String');
    var isFunction = isType('Function');
    这种通过制定部分参数来产生一个新的定制函数的形式就是偏函数

    偏函数在异步编程中十分常见，underscore提供的after方法即是偏函数应用
    _.after = function (times, func) {
      if (times <= 0) return func();
      return function () {
        if (--times < 1) {
          return func.apply(this, arguments);
        }
      };
    };

4.2 异步编程的优势与难点
    
4.2.1 优势
    node带来的最大特性莫过于基于事件驱动的非阻塞I/O模型。
    非阻塞I/O可以使CPU与I/O并不互相依赖等待，让资源得到更好利用。
    对于网络应用而言，并行带来的想象空间更大，延展而开的是分布式和云。并行使得各个单点之间能够更有效地组织起来，这是node在云计算厂商广受青睐的原因

    node实现异步I/O的原理，利用事件循环的方式，js线程像一个分配任务和处理任务的大管家，I/O线程池里的各个I/O都是服务员，负责完成分配的任务。服务员跟管家之间互不依赖，所以可以保持整体的高效率。
    这个模式的缺点则在于管家无法承担过多的细节性任务，如果承担太多会影响到任务的调度，管家忙个不停，服务员得不到活干，整体效率降低

    node是为了解决编程模型中阻塞I/O的性能问题的，采用单线程模型，这导致node更像一个处理I/O密集问题的能手，而CPU密集型则取决于管家的能耐如何

    建议对CPU的好用不要超过10ms，或者将大量的计算分解为诸多销量计算，通过setImmediate进行调度

4.2.2 难点
    1.异常处理
      异步I/O的实现主要包含两个阶段：提交请求和处理结果。这两个阶段中间有事件循环的调度，两者彼此不关联。异步方法则通常在第一个阶段请求后立即返回，因为异常不一定发生在这个阶段，try/catch的功效咋一次出不会发生任何作用。
      异步方法定义：
      var async = function (callback) {
        process.nextTick(callback);
      };
      调用async方法后，callback被存放起来，直到下一个事件循环（Tick）才会取出来执行
      尝试对异步方法进行try/catch操作只能捕获当次事件循环内的异常，对callback执行时抛出的异常将无能为力：
      try {
        async(callback);
      } catch (e) {
        console.log(e);
      }
      node在处理异常上形成了一种约定，将异常作为回调函数的第一个实参传回，如果为空值，则表明异步调用没有异常抛出：
      async(function (err, results){  });

      编写异步方法需要遵循
      1：必须执行调用者传入的回调函数
      2：正确传递回异常供调用者判断

      var async = function (callback) {
        process.nextTick(function() {
          var results = something;
          if (error) {
            return callback(error);
          }
          callback(null, results);
        })
      };

      try {
        req.body = JSON.parse(buf, options.reviver);
      } catch (err) {
        err.body = buf;
        err.status = 400;
        return callback(err);
      }
      callback();
      在编写异步方法时，只要将异常正确传递给用户的回调方法即可，无须过多处理

    2.函数嵌套过深

    3.阻塞代码
      var start = new Date();
      while (new Date() - start < 1000) { }
      这段代码会持续占用CPU进行判断，与真正的线程沉睡相去甚远，完全破坏了事件循环的调度。
      由于node单线程的原因，cpu资源全都会用于为这段代码服务，导致其余任何请求都不会响应
      调用setTimeout效果会更好

    4.多线程编程

    5.异步转同步

4.3 异步编程解决方案
    事件发布/订阅模式
    promise/deferred模式
    流程控制模式

4.3.1 事件发布/订阅模式
    事件监听器模式是一种广泛用于异步编程的模式，是回调函数的事件化，又称发布/订阅模式
    node自身提供的events模块是发布/订阅模式的一个简单实现，node中部分模块都继承自它，具有addListener/on、once、removeListener、removeAllListeners、emit等基本的事件监听模式的方法实现。
    emitter.on('event1', function (message) {
      console.log(message);
    });
    emitter.emit('event1', 'i am msg');
    订阅事件就是一个高阶函数的应用。事件发布/订阅模式可以实现一个事件与多个回调函数的关联，这些回调函数又称为事件侦听器。
    通过emit发布事件后，消息会立即传递给当前事件的所有侦听器执行。侦听器可以很灵活地添加和删除，使得事件和具体处理逻辑之间可以很轻松地关联和解耦
    事件发布/订阅模式自身并无同步和异步调用的问题，但在node中，emit调用多半伴随事件循环而异步触发的，所以我们说事件发布/订阅广泛应用于异步编程
    事件侦听器模式也是一种钩子（hook）机制，利用钩子导出内部数据或状态给外部的调用者

    var options = {
      host: 'www.google.com',
      port: 80,
      path: '/upload',
      method: 'POST',
    };
    var req = http.request(options, function (res) {
      console.log('STATUS:' + res.statusCode);
      console.log('HEADERS:' + JOSN.stringify(res.headers));
      res.on('data', function (chunk) {
        consol.log('BODY:' + chunk);
      });
      res.on('end', function (chunk) {
        //todo
      });
    });
    req.on('error', function (e) {
      console.log('problem with request:' + e.message);
    });
    req.write('data\n');
    req.write('data\n');
    req.end();
    只需关心error、data、end等业务事件

    node对事件发布/订阅机制做的一些额外处理
      1.如果对一个事件添加超过10个侦听器，将会得到一条警告。设计者认为过多侦听器会导致内存泄漏。调用emitter.setMaxListeners(0)可以将这个限制去掉。另一方面，由于事件发布会引起一系列侦听器执行，如果事件相关的侦听器过多，可能存在过多占用CPU的情景
      2.为了处理异常，EventEmitter对象对error事件进行了特殊对待。如果运行期间的错误触发了error事件，EventEmitter会检查是否有对error事件添加过侦听器，如果添加了，这个错误会由该侦听器处理，否则这个错误会作为异常抛出。如果外部没有捕获这个异常，将会引起线程退出。
        一个健壮的EventEmitter实例应该对error事件做处理
        1.继承events模块
          实现一个继承EventEmitter的类是十分简单的：
          var events = require('events');
          function Stream() {
            events.EventEmitter.call(this);
          }
          util.inherits(Stream, events.EventEmitter);
          node在util模块中封装了继承的方法，可以轻松继承EventEmitter类，利用事件机制解决业务问题。
          在node提供的核心模块中，有近半数都继承自EventEmitter
        2.利用事件队列解决雪崩问题
          在事件订阅/发布模式中，通常有once方法，通过它添加的侦听器只能执行一次，执行后会将它与事件的关联移除。
          计算机中，缓存存放在内存中，访问速度快，让绝大多数的请求不必重复发去做一些低效的数据读取。
          雪崩问题就是在高访问量、大并发量的情况下缓存失效的情景，此时大量的请求同时涌入数据库，数据库无法同时承受请求，进而往前影响到网站整体的响应速度

          var select = function (callback) {
            db.select('SQL', function (results) {
              callback(result);
            });
          };
          如果站点刚好启动，这时缓存中不存在数据，如果访问量巨大，同一句SQL会被发送到数据库中反复查询，会影响服务的整体性能。一种改进方案是添加一个状态锁：
          var status = 'ready';
          var select = function (callback) {
            if (status === 'ready') {
              status = 'pending';
              db.select('SQL', function (result) {
                status = 'ready';
                callback(results);
              });
            }
          };
          这种情景下，连续多次调用select时，只有第一次调用生效，后续select是没有数据服务的，这时可以引入事件队列
          var proxy = new events.EventEmitter();
          var status = 'ready';
          var select = function (callback) {
            proxy.once('selected', callback);
            if (status === 'ready') {
              status = 'pending';
              db.select('SQL', function (results) {
                proxy.emit('selected', results);
                status = 'ready';
              });
            }
          };
          利用了once方法，将所有请求的回调都压入事件队列中，利用其执行一次就会将监视器移除的特点，保证每一个回调只会被执行一次。
          对于相同的SQL语句，保证在同一个查询开始到结束的过程中永远只有一次。SQL在进行查询时，新到来的相同调用只需在队列中等待数据就绪即可，一旦查询结束，得到的结果可以被这些调用共同使用。这种方式能节省重复的数据库调用产生的开销
        3.多异步之间的协作方案
          利用高阶函数的优势，侦听器作为回调函数可以随意添加和删除
          var count = 0;
          var results = {};
          var done = function (key, value) {
            results[key] = value;
            count++;
            if (count === 3) {
              render(results);
            }
          };
          fs.readFile(template_path, 'utf8', function (err, template) {
            done('template', template);
          });
          db.query(sql, function (err, data) {
            done('data', data);
          });
          l1On.get(function (err, resources) {
            done('resources', resources);
          });

          由于多个异步场景中回调函数的执行并不能保证顺序，且回调函数之间互相没有交集，所以需要借助一个第三方函数或变量来处理异步协作的结果。把这个用于检测次数的变量叫做哨兵变量
          var after = function (times, callback) {
            var count = 0;
            var results = {};
            return function (key, value) {
              results[key] = value;
              count++;
              if (count === times) {
                callback(results);
              }
            };
          };
          var done = after(times, render);
          上述方案实现了多对一的目的。可以利用事件发布/订阅方式来完成多对多的方案：
          var emitter = new events.Emitter();
          var done = after(times, render);
          emitter.on('done', done);
          emitter.on('done', other);
          fs.readFile(template_path, 'utf8', function (err, template) {
            emitter.emit('done', 'template', template);
          });
          db.query(sql, function (err, data) {
            emitter.emit('done', 'data', data);
          });
          l1On.get(function (err, resources) {
            emitter.emit('done', 'resources', resources);
          });
          这种方案结合了前者用简单的偏函数完成多对一的收敛和事件订阅/发布模式中一对多的发散。
          
          作者的EventProxy模块，它是对事件订阅/发布模式的扩充，可以自由订阅组合事件
          var proxy = new EventProxy();
          proxy.all('template', 'data', 'resources', function (template, data, resources) {  });
          fs.readFile(template_path, 'utf8', function (err, template) {
            proxy.emit('template', template);
          };
          db.query(sql, function (err, data) {
            proxy.emit('data', data);
          });
          l1On.get(function (err, resources) {
            proxy.emit('resources', resources);
          });
          EventProxy提供了一个all方法来订阅多个事件，当每个事件都被触发后，侦听器才会执行。
          tail方法与all方法区别在于all方法的侦听器在满足条件之后只会执行一次，tail方法的侦听器则在满足条件执行一次后，如果组合事件中的某个事件被再次触发，侦听器会用最新的数据继续执行。
          all方法带来的另一个改进是：在侦听器中返回数据的参数列表与订阅组合事件的事件列表是一致对应的
          EventProxy提供了after方法来实现事件在执行多少次后执行侦听器的单一事件组合订阅方式
          var proxy = new EventProxy();
          proxy.after('data', 10, function (datas) { });
          这段代码表示执行10次data事件后执行侦听器，这个侦听器得到的数据为10次按事件触发次序排序的数组
        4.EventProxy的原理
          EventProxy来自于backbone的事件模块，在每个非all事件触发时都会触发一次all事件
          EventProxy将all当做一个事件流的拦截层，在其中注入一些业务来处理单一事件无法解决的异步处理问题
        5.EventProxy的异常处理
          EventProxy在事件发布/订阅模式的基础上还完善了异常处理。

4.3.2 Promise/Deferred模式 
    Promise/Deferred模式包含Promise和Deferred两部分
    1.Promise/A （commonjs草案抽象的异步promise/deferred模型）
      promise操作只会处在3中状态的一种：未完成态、完成态和失败态
      promise的状态只会出现从未完成态向完成态或失败态转化，不能逆反。完成态和失败态不能互相转化
      promise的状态一旦转化，将不能被更改
    对于then方法
      接受完成态、错误态的回调方法。在操作完成或出现错误时，将会调用对应方法
      可选地支持progress事件回调作为第三个方法
      then方法只接受function对象，其余对象将被忽略
      then方法继续返回promise对象以实现链式调用
    then方法的定义：then(fulfilledHandler, errorHandler, progressHandler)
    一个通过继承node的events模块的简单实现：
    var Promise = function() {
      EventEmitter.call(this);
    };
    util.inherits(Promise, EventEmitter);
    Promise.prototype.then = function (fulfilledHandler, errorHandler, progressHandler) {
      //利用once方法保证成功回调只执行一次
      typeof fulfilledHandler === 'function' && this.once('success', fulfilledHandler);
      
      typeof errorHandler === 'function' && this.once('error', errorHandler);

      typeof progressHandler === 'function' && this.on('progress', progressHandler);

      return this;
    }
    为了完成整个流程，还需要触发执行这些回调函数的地方，实现这些功能的对象通常称为deferred，即延迟对象
    var Deferred = function () {
      this.state = 'undefined';
      this.promise = new Promise();
    };
    Deferred.prototype.resolve = function (obj) {
      this.state = 'fulfilled';
      this.promise.emit('success', obj);
    };
    Deferred.prototype.reject = function (err) {
      this.state = 'failed';
      this.promise.emit('error', err);
    };
    Deferred.prototype.progress = function (data) {
      this.promise.emit('progress', data);
    };
    利用Promise/A提议的模式，对一个典型的响应对象进行封装：
    res.setEncoding('utf8');
    res.on('data', function (chunk) {
      console.log('body:' + chunk);
    });
    res.on('end', function () { /*done*/ });
    res.on('error', function (err) { /*error*/ });
    转换为：
    res.then(function () { /*done*/ }, function () { /*error*/ }, function (chunk) { console.log(chunk) });

    Deferred主要是用于内部，用于维护异步模型的状态；Promise则作用于外部，通过then方法暴露给外部以添加自定义逻辑

    2.Promise中的多异步协作
      deferred.all

    3.promise的进阶知识
      支持序列执行的promise
      将APIpromise化

4.3.3 流程控制库
    1.尾触发与next
      需要手工调用才能持续执行后续调用
    2.async
      异步的串行执行
      异步的并行执行
      异步调用的依赖处理
      自动依赖处理
    3.Step

4.4 异步并发控制
    同步I/O因为每个I/O都是彼此阻塞，在循环体中，总是一个接着一个调用，不会出现耗用文件描述符太多的情况，同时性能也是低下的；对于异步I/O，虽然并发容易实现，依然需要控制，需要给予过载保护

4.4.1 bagpipe的解决方案
    通过一个队列来控制并发量
    如果当前活跃（指调用发起但未执行回调）的异步调用量小于限定值，从队列中取出执行
    如果活跃调用达到限定值，调用暂时存放在队列中
    每个异步调用结束时，从队列取出新的异步调用执行

4.4.2 async的解决方案
    async提供了一个方法处理异步调用的限制：parallelLimit


第5章
5.1 v8的垃圾回收机制与内存限制
  
5.1.1 node与v8
    
5.1.2 v8的内存限制
    一般后端语言在内存使用上没有什么限制，但node中通过js使用内存只能使用部分（64位系统约为1.4GB，32位系统约为0.7GB）。会导致node无法直接操作大内存对象，无法将一个2GB的文件读入内存中进行字符串分析处理。这样在单个node进程的情况下，计算机的内存资源无法得到充足使用
    原因在于node基于V8构建，所以node中使用的js对象基本上都是通过v8自己的方式来进行分配和管理。浏览器端是够用了，但在node中却限制了开发者使用内存

5.1.3 v8的对象分配
    在v8中，所有js对象都是通过堆来进行分配的，node提供了v8中内存使用量的查看方式
    process.memoryUsage();
    { rss: 20824064, heapTotal: 8425472, heapUsed: 3997400, external: 13064 }
    heapTotal是已申请到的堆内存 heapUsed是当前使用量
    当我们声明变量并赋值时，所使用对象的内存就分配在堆中。如果已申请的堆空闲内存不够分配新的对象，将继续申请堆内存，直到堆大小超过V8限制
    v8限制大小原因是因为v8最初为浏览器设计，不太可能遇到大量内存的场景。
    深层原因是因为v8的垃圾回收机制的限制，以1.5GB的垃圾回收堆内存为例，v8做一次小的垃圾回收需要50毫秒以上，做一次非增量式的垃圾回收甚至要1秒以上。这是垃圾回收中引起js线程暂停的时间。
    v8提供了选项让我们使用更多的内存，node在启动时可以传递--max-old-space-size或--max-new-space-size来调整内存大小：
    node --max-old-space-size=1700 test.js //单位为MB
    node --max-new-space-size=1024 test.js //单位为KB
    一旦生效无法动态改变，如果遇到node无法分配足够内存给js对象的情况，可以这样来放宽v8默认的内存限制

5.1.4 v8的垃圾回收机制
    1.v8主要的垃圾回收算法
      v8的垃圾回收策略主要基于分代式垃圾回收机制。
      没有一种垃圾回收算法能够胜任所有场景，按统计学方法，现代的垃圾回收算法中安对象的存活时间将内存的垃圾回收进行不同的分代，然后分别对不同分代的内存施以更高效的算法

      v8的内存分代
      v8中主要讲内存分为新生代和老生代两代。新生代中的对象为存或时间较短的对象，老生代为存活时间较长或常驻内存的对象
      v8堆的整体大小就是新生代所用空间加上老生代的内存空间。
      --max-old-space-size可以用于设置老生代内存空间的最大值
      --max-new-space-size用于设置新生代内存空间的大小

      scavenge算法
      新生代中的对象主要通过scavenge算法进行垃圾回收。scavenge具体实现中采用了Cheney算法
      Cheney算法采用复制的方式实现的垃圾回收算法。

      Mark-sweep & Mark-compact
      老生代主要算法

      incremental marking
      v8引入增量标记的改进后，垃圾回收的最大停顿时间可以减少到原本的1/6

5.1.5 查看垃圾回收日志
    启动时添加--trace_gc参数。在进行垃圾回收时，将会从标准输出中打印垃圾回收的日志信息
    node --trace_gc -e "var a = []; for (var i = 0; i < 1000000; i++) a.push(new Array(100));" > gc.log
    通过日志可以找出垃圾回收哪些阶段比较耗时，触发原因是什么。
    通过在node启动时使用--prof参数，可以得到v8执行时的性能分析数据，其中包含了垃圾回收执行时占用的时间。
    v8提供了linux-tick-processor工具用于统计日志信息，在node源码deps/v8/tools目录，windows对应命令文件为windows-tick-processor.bat。将该目录添加到环境变量PATH中，即可直接调用：
    linux-tick-processor v8.log

5.2 高效实用内存

5.2.1 作用域
    在js中能形成作用域的有函数调用、with以及全局作用域
    var foo = function () { var local = {}; };
    foo函数在每次被调用时会创建对应的作用域，函数执行结束后作用域会销毁。同时作用域中声明的局部变量分配在该作用域上，随作用域的销毁而销毁。只被局部变量引用的对象存活周期较短。由于local对象很小，分配在新生代的from空间中。在作用域释放后，局部变量local失效，其引用的对象将会在下次垃圾回收时被释放

    1.标识符查找
      与作用域相关的即使标识符查找。
      js在执行时会查找变量定义在哪里，先查找当前作用域，然后向上级作用域查找，直到查到为止
    2.作用域链
      变量往上查找，一直到全局作用域，这样的查找方式使得作用域想一个链条。
    3.变量的主动释放
      全局作用域需要到进程退出才能释放，导致全局变量常驻内存（老生代中）。如果需要释放常驻内存的对象，可以通过delete操作来删除引用关系。或者将变量重新赋值，让旧的对象脱离引用关系。在接下来的老生代内存清除和整理的过程中，会被回收释放
      global.foo = 'global'; 
      delete global.foo; || global.foo = undefined; || global.foo = null;
      在非全局作用域中，这样也能主动释放变量引用的对象。
      delete和重新赋值具有相同效果，但v8中通过delete删除对象的属性有可能干扰v8的优化，所以还是赋值好

5.2.2 闭包
    在JS中，实现外部作用域访问内部作用域中变量的方法叫闭包。
    得益于高阶函数的特性：函数可以作为参数或者返回值。
    var foo = function () {
      var bar = function () {
        var local = '局部';
        return function () {
          return local;
        };
      };
      var end = bar();//访问内部变量
      console.log(end);
    }
    一旦有变量引用这个中间函数，这个函数不会被释放，也会使得原始的作用域不会释放，作用域中产生的内存占用也不会释放。除非不在有引用，才会逐步释放

5.2.3 小结

5.3 内存指标
    
5.3.1 查看内存使用情况
    os模块中totalmem和freemem方法可以查看内存使用情况
    1.查看进程的内存占用
      调用process.memoryUsage可以看到node进程的内存占用情况。rss是resident set size的缩写，即进程的常驻内存部分。进程的内存总共有几部分，一部分时rss，其余部分在交换区(swap)或者文件系统(filesystem)中
    2.查看系统的内存占用
      与process.memoryUsage不同的是，os模块方法用于查看操作系统的内存使用情况。
      系统总内存：os.totalmem() 
      系统闲置内存：os.freemem()

5.3.2 堆外内存  
    堆中的内存总量总是小于进程的常驻内存用量，意味着ndoe中内存使用并非都是通过v8分配，我们将那些不是通过v8分配的内存称为堆外内存
    堆外内存可以突破内存限制的问题

5.3.3 小结
   node的内存构成主要通过v8进行分配的部分和node自行分配的部分，受v8的垃圾回收限制的主要是v8的堆内存

5.4 内存泄漏
    应当回收的对象出现意外而没有回收，变成了常驻在老生代的对象
    一般，造成内存泄漏原因：缓存、队列消费不及时、作用域未释放

5.4.1 慎将内存当做缓存
    缓存访问效率高，可以节省I/O时间。在node中，一个对象呗当做缓存使用，意味着它将常驻在老生代。缓存中存储的键越多，长期存活的对象就越多，导致垃圾回收在进行扫描和整理时，对这些对象做无用功
    严格意义的缓存有完善的过期策略，普通对象的键值没有。
    1.缓存限制策略
      limitablemap模块，记录键在数组中，一旦超过数量，就以先进先出的方式进行淘汰
      一般模块最好添加清空队列的相应接口，以供调用者释放内存
    2.缓存的解决方案
    进程之间无法共享内存，目前方案是采用进程外的缓存，进程自身不存储状态。外部的缓存不会影响node进程的性能。在node中可以解决两个问题：
    1，将缓存转移到外部，减少常驻内存的对象的数量，让垃圾回收更加高效
    2，进程之间可以共享缓存
    较好的缓存有redis和memcached

5.4.2 关注队列状态
    监控队列长度；异步调用应该包含超时机制；

5.5 内存泄漏排查
    工具：v8-profiler、node-heapdump、node-mtrace、dtrace、node-memwatch

5.5.1 node-heapdump
    p131  

5.5.2 node-memwatch
    p132

5.5.3 小结

5.6 大内存应用
    node提供stream模块处理大文件，stream是node原生模块，node中大多数模块都有stream的应用，比如fs的createReadStream()和createWriteStream可以创建文件的可读流和可写流，process模块中stdin和stdout分别是可读流和可写流的实例。
    由于v8限制，需要用fs.createReadStream和fs.createWriteStream直接进行大文件的操作
    可读流提供了管道方法pipe，封装了data事件和写入操作。
    如果不进行字符串层面操作，则不需要借助v8处理，可以进行纯粹的buffer操作，这不会受到v8堆内存限制。但是v8虽然不限制堆内存大小，物理内存依然有限制


第6章 理解buffer
在网络流和文件操作中，node中需要处理大量二进制数据，js自由字符串不能满足，于是buffer对象应运而生

6.1 buffer结构
    buffer是一个像array的对象，但它主要用于操作字节

6.1.1 模块结构
    buffer将性能相关部分用C++实现，非性能部分是JS实现。buffer在全局对象上

6.1.2 buffer对象
    buffer对象类似于数组，它的元素为16进制的两位数，0-255的数值
    var str = 'a'; var buf = new Buffer(str, 'utf-8'); console.log(buf);
    // <Buffer 61>
    buffer可以访问length属性得到长度，可以通过下标访问元素。
    给元素的赋值如果小于0，就将该值逐次加256，直到得到一个0-255之间的整数。如果得到数值大于255，就逐次减256，直到得到0-255之间的数值。如果是小数，就舍弃小数部分，只保留整数部分
    new Buffer(100)[10] = -100

6.1.3 buffer内存分配


     
        
        
        
        
        
        
        
        
        
